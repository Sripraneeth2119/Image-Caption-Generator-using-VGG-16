{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Image Caption Generation** "]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-06T03:42:42.858632Z","iopub.status.busy":"2023-10-06T03:42:42.858259Z","iopub.status.idle":"2023-10-06T03:42:52.099694Z","shell.execute_reply":"2023-10-06T03:42:52.098754Z","shell.execute_reply.started":"2023-10-06T03:42:42.858607Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np \n","import pickle\n","from tqdm.notebook import tqdm # giving us a UI on how much data is processed\n","\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.preprocessing.text import Tokenizer \n","from tensorflow.keras.preprocessing.sequence import pad_sequences  \n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.layers import Input,Dense,LSTM,Embedding, Dropout, add"]},{"cell_type":"markdown","metadata":{},"source":["I have used the pad_sequence in order to even out all the texts available in the dataset. Like Some sentences will have 5 words and others will have some where around 10, then we will be having an unbalanced data for input. Thus using pad_sequence will probably help us to avoid this problem.\n","I have used plot_model, this will give us the clear represenation of the whole model in terms of an image.\n","'tqdm' can help you create progress bars for data processing, training machine learning models, multi-loop Python function, and downloading data from the internet."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T03:43:21.224987Z","iopub.status.busy":"2023-10-06T03:43:21.224345Z","iopub.status.idle":"2023-10-06T03:43:21.229354Z","shell.execute_reply":"2023-10-06T03:43:21.228416Z","shell.execute_reply.started":"2023-10-06T03:43:21.224956Z"},"trusted":true},"outputs":[],"source":["BASE_DIR = 'E:\\Personal Project\\Image Caption Generator\\data'\n","WORKING_DIR = 'E:\\Personal Project\\Image Caption Generator\\working'"]},{"cell_type":"markdown","metadata":{},"source":["## Extract Image Feature"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T03:43:37.481480Z","iopub.status.busy":"2023-10-06T03:43:37.481152Z","iopub.status.idle":"2023-10-06T03:43:46.341259Z","shell.execute_reply":"2023-10-06T03:43:46.340521Z","shell.execute_reply.started":"2023-10-06T03:43:37.481455Z"},"trusted":true},"outputs":[],"source":["model = VGG16()\n","\n","#restructure our VGG16 model\n","model = Model(inputs=model.inputs,outputs=model.layers[-2].output)\n","\n","print(model.summary())"]},{"cell_type":"markdown","metadata":{},"source":["Here we have reconstructed because, we don't need the prediction layer of the VGG16 model. We just need the rest of the modele except the prediction part and thus we have reconstructed the model "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T03:43:57.575212Z","iopub.status.busy":"2023-10-06T03:43:57.574852Z","iopub.status.idle":"2023-10-06T03:58:52.664161Z","shell.execute_reply":"2023-10-06T03:58:52.663240Z","shell.execute_reply.started":"2023-10-06T03:43:57.575184Z"},"trusted":true},"outputs":[],"source":["#extract features from image\n","features = {}\n","directory= os.path.join(BASE_DIR, 'Images')\n","\n","#iterating through all the images in the directory\n","for img in tqdm(os.listdir(directory)):\n","    # load the image from file\n","    imgpath = directory + '/' + img\n","    image = load_img(imgpath, target_size=(224,224))\n","    #Convert into numpy array\n","    image = img_to_array(image)\n","    #reshape\n","    image = image.reshape((1,image.shape[0],image.shape[1],image.shape[2]))\n","    #preprocess for VGG16\n","    image = preprocess_input(image)\n","    #extract features\n","    feature = model.predict(image,verbose=0)\n","    #get image id\n","    image_id = img.split('.')[0]\n","    # store featues\n","    features[image_id] = feature"]},{"cell_type":"markdown","metadata":{},"source":["The verbose is zero inorder to say that there is no additional texts and will be clean."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T03:58:54.950318Z","iopub.status.busy":"2023-10-06T03:58:54.949975Z","iopub.status.idle":"2023-10-06T03:58:55.234370Z","shell.execute_reply":"2023-10-06T03:58:55.233394Z","shell.execute_reply.started":"2023-10-06T03:58:54.950291Z"},"trusted":true},"outputs":[],"source":["#store features in pickle\n","pickle.dump(features,open(os.path.join(WORKING_DIR, 'features.pickle'),'wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:00:15.731543Z","iopub.status.busy":"2023-10-06T04:00:15.731212Z","iopub.status.idle":"2023-10-06T04:00:15.854095Z","shell.execute_reply":"2023-10-06T04:00:15.853151Z","shell.execute_reply.started":"2023-10-06T04:00:15.731516Z"},"trusted":true},"outputs":[],"source":["#load features from pickle\n","with open(os.path.join(WORKING_DIR,'features.pickle'),'rb' ) as f:\n","    features = pickle.load(f)"]},{"cell_type":"markdown","metadata":{},"source":["## Load the Captions Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:00:18.585429Z","iopub.status.busy":"2023-10-06T04:00:18.585106Z","iopub.status.idle":"2023-10-06T04:00:20.568254Z","shell.execute_reply":"2023-10-06T04:00:20.567312Z","shell.execute_reply.started":"2023-10-06T04:00:18.585402Z"},"trusted":true},"outputs":[],"source":["with open(os.path.join(BASE_DIR,'captions.txt'), 'r') as f:\n","    next(f)\n","    caption = f.read()"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-10-06T04:00:27.063690Z","iopub.status.busy":"2023-10-06T04:00:27.063363Z","iopub.status.idle":"2023-10-06T04:00:27.147928Z","shell.execute_reply":"2023-10-06T04:00:27.146768Z","shell.execute_reply.started":"2023-10-06T04:00:27.063663Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["caption"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:00:31.781543Z","iopub.status.busy":"2023-10-06T04:00:31.781030Z","iopub.status.idle":"2023-10-06T04:00:31.951315Z","shell.execute_reply":"2023-10-06T04:00:31.950274Z","shell.execute_reply.started":"2023-10-06T04:00:31.781496Z"},"trusted":true},"outputs":[],"source":["#Create mapping image to Caption\n","mapping = {}\n","for line in tqdm(caption.split('\\n')):\n","    #split the line captions by comma(,)\n","    tokens = line.split(',')\n","    if len(line) < 2:\n","        continue # We are doing this because, since the len is less than 2 then we don't need this or optional one \n","    image_id, cap = tokens[0], tokens[1:]\n","    #remove extension from image ID\n","    image_id = image_id.split('.')[0]\n","    #Convert caption list into string\n","    cap = \" \".join(cap)\n","    # Create list for multiple captions available for the same image\n","    if image_id not in mapping:\n","        mapping[image_id] = []\n","    #Store caption\n","    mapping[image_id].append(cap)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:30.521481Z","iopub.status.busy":"2023-10-06T04:01:30.521119Z","iopub.status.idle":"2023-10-06T04:01:30.528094Z","shell.execute_reply":"2023-10-06T04:01:30.527067Z","shell.execute_reply.started":"2023-10-06T04:01:30.521453Z"},"trusted":true},"outputs":[],"source":["len(mapping)"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing Text"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:33.028039Z","iopub.status.busy":"2023-10-06T04:01:33.027395Z","iopub.status.idle":"2023-10-06T04:01:33.033891Z","shell.execute_reply":"2023-10-06T04:01:33.032915Z","shell.execute_reply.started":"2023-10-06T04:01:33.028007Z"},"trusted":true},"outputs":[],"source":["def clean(map):\n","    for key, captions in mapping.items():\n","        for i in range(len(captions)):\n","            caption = captions[i]\n","            #preprocessing steps\n","            caption = caption.lower()\n","            caption = caption.replace('[^A-Za-z]','') # Removing all the numbers and characters\n","            caption = caption.replace('\\s+',' ') # If there are multiple spaces, then we will just replace with single space \n","            # Add start and end tags which would help us to stop the prediction and also we are neglecting terms like small words like a, is etc\n","            caption = 'startseq ' + ' '.join([word for word in caption.split() if len(word)>1]) + ' endseq'\n","            captions[i] = caption"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:42.119602Z","iopub.status.busy":"2023-10-06T04:01:42.119265Z","iopub.status.idle":"2023-10-06T04:01:42.125499Z","shell.execute_reply":"2023-10-06T04:01:42.124606Z","shell.execute_reply.started":"2023-10-06T04:01:42.119574Z"},"trusted":true},"outputs":[],"source":["#before preprocess the text\n","mapping['1000268201_693b08cb0e']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:45.704363Z","iopub.status.busy":"2023-10-06T04:01:45.703731Z","iopub.status.idle":"2023-10-06T04:01:45.806848Z","shell.execute_reply":"2023-10-06T04:01:45.805880Z","shell.execute_reply.started":"2023-10-06T04:01:45.704333Z"},"trusted":true},"outputs":[],"source":["# After Preprocessing the text\n","clean(mapping)\n","mapping['1000268201_693b08cb0e']"]},{"cell_type":"markdown","metadata":{},"source":["Now here we can see that the short words such as A,I,etc are eliminated just like the work we do using Stopwords but then stopwords will also elminate other factors which are not having much weightage for the word. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:47.813137Z","iopub.status.busy":"2023-10-06T04:01:47.812167Z","iopub.status.idle":"2023-10-06T04:01:47.827803Z","shell.execute_reply":"2023-10-06T04:01:47.826721Z","shell.execute_reply.started":"2023-10-06T04:01:47.813093Z"},"trusted":true},"outputs":[],"source":["all_captions = []\n","for key in mapping:\n","    for caption in mapping[key]:\n","        all_captions.append(caption)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:49.631679Z","iopub.status.busy":"2023-10-06T04:01:49.631360Z","iopub.status.idle":"2023-10-06T04:01:49.638381Z","shell.execute_reply":"2023-10-06T04:01:49.637513Z","shell.execute_reply.started":"2023-10-06T04:01:49.631653Z"},"trusted":true},"outputs":[],"source":["all_captions[:10]"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenization of Captions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:51.984431Z","iopub.status.busy":"2023-10-06T04:01:51.984096Z","iopub.status.idle":"2023-10-06T04:01:52.499781Z","shell.execute_reply":"2023-10-06T04:01:52.498907Z","shell.execute_reply.started":"2023-10-06T04:01:51.984404Z"},"trusted":true},"outputs":[],"source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(all_captions)\n","voc_size = len(tokenizer.word_index)+1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:54.098815Z","iopub.status.busy":"2023-10-06T04:01:54.098191Z","iopub.status.idle":"2023-10-06T04:01:54.104578Z","shell.execute_reply":"2023-10-06T04:01:54.103607Z","shell.execute_reply.started":"2023-10-06T04:01:54.098783Z"},"trusted":true},"outputs":[],"source":["voc_size"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:55.218926Z","iopub.status.busy":"2023-10-06T04:01:55.218271Z","iopub.status.idle":"2023-10-06T04:01:55.248193Z","shell.execute_reply":"2023-10-06T04:01:55.247086Z","shell.execute_reply.started":"2023-10-06T04:01:55.218883Z"},"trusted":true},"outputs":[],"source":["#get max len of caption available because we are gonna use this in padding the sequence\n","max_len = max(len(caption.split()) for caption in all_captions)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:56.867391Z","iopub.status.busy":"2023-10-06T04:01:56.867073Z","iopub.status.idle":"2023-10-06T04:01:56.873707Z","shell.execute_reply":"2023-10-06T04:01:56.872730Z","shell.execute_reply.started":"2023-10-06T04:01:56.867365Z"},"trusted":true},"outputs":[],"source":["max_len"]},{"cell_type":"markdown","metadata":{},"source":["## Train Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:01:59.815163Z","iopub.status.busy":"2023-10-06T04:01:59.814473Z","iopub.status.idle":"2023-10-06T04:01:59.820358Z","shell.execute_reply":"2023-10-06T04:01:59.819404Z","shell.execute_reply.started":"2023-10-06T04:01:59.815129Z"},"trusted":true},"outputs":[],"source":["image_ids = list(mapping.keys())\n","split = int(len(image_ids) * 0.90)\n","train = image_ids[:split]\n","test = image_ids[split:]"]},{"cell_type":"markdown","metadata":{},"source":["Now we will create a data generator in order to fetch image and caption like in batch size so that it will be easy for us to load into the model and train it orelse it consumes more RAM"]},{"cell_type":"markdown","metadata":{},"source":["Here during after tokenizing, we will split into X and y such that initially X will have nothing while y have the first word in the sentence, then further the word present in y is moved to X and y will get the second word of the sentense"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:04:32.289607Z","iopub.status.busy":"2023-10-06T04:04:32.289282Z","iopub.status.idle":"2023-10-06T04:04:32.297635Z","shell.execute_reply":"2023-10-06T04:04:32.296745Z","shell.execute_reply.started":"2023-10-06T04:04:32.289582Z"},"trusted":true},"outputs":[],"source":["#creating data generator (Avoids session from crashing)\n","def  data_generator(data_keys,mapping,features,tokenizer,max_len,voc_size,batch_size):\n","    #loop over images \n","    X1, X2,y = list(),list(),list()\n","    n = 0 #used to determine whether we reach the batch size = 0\n","    \n","    while 1:\n","        for key in data_keys:\n","            n +=1\n","            captions = mapping[key]\n","            for caption in captions:\n","                #encode the sequence\n","                sequence = tokenizer.texts_to_sequences([caption])[0]\n","                # split the sequence into X,Y parts\n","                for i in range (1,len(sequence)):\n","                    in_sequence, out_sequence = sequence[:i], sequence[i]\n","                    #pad input sequence in order to have a common length\n","                    in_sequence = pad_sequences([in_sequence],maxlen=max_len)[0]\n","                    #encode output sequence\n","                    out_sequence = to_categorical([out_sequence], num_classes=voc_size)[0]\n","                    # The Categorical will be converting the word into one hot encoding\n","                    \n","                    #store the sequences\n","                    X1.append(features[key][0])\n","                    X2.append(in_sequence)\n","                    y.append(out_sequence)\n","            if n == batch_size:\n","                X1,X2,y = np.array(X1), np.array(X2), np.array(y)\n","                yield [X1,X2],y\n","                X1, X2,y = list(),list(),list()\n","                n = 0"]},{"cell_type":"markdown","metadata":{},"source":["Here X1 and X2 are the input features and y will be the target or output. Here previous we are iterating in the for loop until n is equal to the batch size and once it's equal then we are reseting X1,X2,y values for the next loop."]},{"cell_type":"markdown","metadata":{},"source":["## Model Creation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:07:05.641729Z","iopub.status.busy":"2023-10-06T04:07:05.640746Z","iopub.status.idle":"2023-10-06T04:07:06.788161Z","shell.execute_reply":"2023-10-06T04:07:06.787277Z","shell.execute_reply.started":"2023-10-06T04:07:05.641683Z"},"trusted":true},"outputs":[],"source":["#Encoder model\n","# image feature layers\n","inputs1 = Input(shape=(4096,))\n","feature1 = Dropout(0.4)(inputs1)\n","feature2 = Dense(256,activation='relu')(feature1)\n","# Text feature layer\n","inputs2 = Input(shape=(max_len,))\n","se1 = Embedding(voc_size,256,mask_zero=True)(inputs2) # Since we are padding the sentence we take mask Zero\n","se2 = Dropout(0.4)(se1)\n","se3 = LSTM(256)(se2)\n","\n","#Decoder model\n","decoder1 = add([feature2,se3])\n","decoder2 = Dense(256,activation='relu')(decoder1)\n","outputs = Dense(voc_size, activation = \"softmax\")(decoder2)\n","\n","model = Model(inputs=[inputs1,inputs2],outputs=outputs)\n","model.compile(loss='categorical_crossentropy', optimizer ='adam')\n","\n","#plot the model.\n","plot_model(model, show_shapes=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-06T04:07:51.614527Z","iopub.status.busy":"2023-10-06T04:07:51.614199Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["epochs = 2000\n","batch_size = 32\n","steps = len(train)//batch_size #After each step the system will do back propagation\n","\n","for i in range(epochs):\n","    generator = data_generator(train,mapping,features,tokenizer,max_len,voc_size,batch_size)\n","    model.fit(generator, epochs =1, steps_per_epoch=steps, verbose =1) \n"]},{"cell_type":"markdown","metadata":{},"source":["## Save the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-03T22:50:20.161893Z","iopub.status.busy":"2023-08-03T22:50:20.161445Z","iopub.status.idle":"2023-08-03T22:50:20.308540Z","shell.execute_reply":"2023-08-03T22:50:20.307448Z","shell.execute_reply.started":"2023-08-03T22:50:20.161851Z"},"trusted":true},"outputs":[],"source":["model.save(WORKING_DIR+'/image_caption_generator.h5')"]},{"cell_type":"markdown","metadata":{},"source":["## Generation Captions for the Image"]},{"cell_type":"markdown","metadata":{},"source":["Initially we have to convert the index to the word."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-03T22:51:29.588797Z","iopub.status.busy":"2023-08-03T22:51:29.588425Z","iopub.status.idle":"2023-08-03T22:51:29.594325Z","shell.execute_reply":"2023-08-03T22:51:29.592973Z","shell.execute_reply.started":"2023-08-03T22:51:29.588764Z"},"trusted":true},"outputs":[],"source":["def idx_to_word(integer,tokenizer):\n","    for word,index in tokenizer.word_index.items():\n","        if index == integer:\n","            return word\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-03T23:04:34.595025Z","iopub.status.busy":"2023-08-03T23:04:34.594626Z","iopub.status.idle":"2023-08-03T23:04:34.603185Z","shell.execute_reply":"2023-08-03T23:04:34.602028Z","shell.execute_reply.started":"2023-08-03T23:04:34.594991Z"},"trusted":true},"outputs":[],"source":["def predict_caption(model,image,tokenizer,max_length):\n","    in_text ='startseq'\n","    #once started, it should iterate over the max length of sequence \n","    for i in range(max_length):\n","        sequence = tokenizer.texts_to_sequences([in_text])[0]\n","        #pad the sequence\n","        sequence = pad_sequences([sequence],max_length)\n","        #predict next word\n","        y1 = model.predict([image,sequence],verbose=0)\n","        # get index with high probability \n","        y1 = np.argmax(y1) #argmax will give us the maximum probability\n","        # convert index to word\n","        word = idx_to_word(y1,tokenizer)\n","        #stop if word not found\n","        if word is None:\n","            break\n","        #append word as i/p for generating next word\n","        in_text+= \" \" + word\n","        if word == 'endseq':\n","            break\n","    return in_text"]},{"cell_type":"markdown","metadata":{},"source":["## Validate the Text Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-03T23:04:37.875505Z","iopub.status.busy":"2023-08-03T23:04:37.874791Z"},"trusted":true},"outputs":[],"source":["from nltk.translate.bleu_score import corpus_bleu\n","actual, predicted = list(), list()\n","\n","for key in tqdm(test):\n","    captions = mapping[key] # Actual Caption\n","    y_pred = predict_caption(model,features[key],tokenizer,max_len)\n","    \n","    act_cap = [caption.split() for caption in captions]\n","    y_pred = y_pred.split()\n","    \n","    actual.append(act_cap)\n","    predicted.append(y_pred)\n","    \n","# Calculate BLEU score\n","print('BLEU-1: %f' %corpus_bleu(actual,predicted,weigths=(1.0,0,0,0)))\n","print('BLEU-2: %f' %corpus_bleu(actual,predicted,weigths=(0.5,0.5,0,0)))"]},{"cell_type":"markdown","metadata":{},"source":["## Visualize the Results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","image_name = \"\"\n","image_id = image_name.split('.')[0]\n","img_path = os.path.join(BASE_DIR,\"Images\", image_name)\n","image = Image.open(img_path)\n","captions = mapping[image_id]\n","print('--------------Actual-------------')\n","for caption in captions:\n","    print(caption)\n","ypred = predict_caption(model,feature[image_id], tokenizer, max_len)\n","print('--------------Predicted-------------')\n","print(ypred)\n","plt.imshow(image)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":623289,"sourceId":1111676,"sourceType":"datasetVersion"}],"dockerImageVersionId":30528,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
